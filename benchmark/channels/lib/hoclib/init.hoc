{load_file("nrngui.hoc")}
{load_file("netparmpi.hoc")}
{load_file("defvar.hoc")}
{load_file("timeit.hoc")}
{load_file("load_morphology.hoc")}

default_var("arg_tstop", 100)
default_var("arg_target_count", 22)
// This can be one of: all, hippo, sscx
// The default (all) is the union of gippo and sscx
default_var("arg_model", "all")
default_var("arg_coreneuron", 0)
default_var("arg_coreneuron_gpu", 0)
default_var("arg_coreneuron_filemode", 0)
default_var("arg_dump_coreneuron_model", 0)
default_var("arg_datapath", ".")
default_var("arg_prcell_gid", -1)

use_coreneuron = arg_coreneuron
use_coreneuron_gpu = arg_coreneuron_gpu
use_coreneuron_filemode = arg_coreneuron_filemode
dump_coreneuron_model = arg_dump_coreneuron_model
tstop = arg_tstop
prcell_gid = arg_prcell_gid

objref pnm, coreConfig
targetCount = arg_target_count
pnm = new ParallelNetManager(targetCount)

//timeit_init(pnm.pc)
//{timeit_setVerbose(pnm.myid==0)}

coreConfig = new CoreConfig()

objref typeFile, typeString
objref morphList, etypeList, cellList, cellInst, morph

strdef meFilePath
sprint(meFilePath,"%s/%s/melist.txt", arg_datapath, arg_model)
typeFile = new File(meFilePath)
{typeFile.ropen()}

morphList = new List()
etypeList = new List()

typeString = new String()

// to speed up loading cells, keep list of those already loaded
objref morphLookup
morphLookup = new PythonObject()
morphLookup = morphLookup.dict()

// need HOC_LIBRARY_PATH to include "x/selected_hoc"
typeCount = typeFile.scanvar()
if( pnm.myid == 0 ) { print "Loading ", typeCount, " templates" }
for typeIndex=0, typeCount-1 {
    morphList.append( new String() )
    etypeList.append( new String() )
    typeFile.scanstr( morphList.o(typeIndex).s )
    typeFile.scanstr( etypeList.o(typeIndex).s )

    // must load etype hoc file
    sprint( typeString.s, "%s.hoc", etypeList.o(typeIndex).s )
    {load_file( typeString.s )}
}
{typeFile.close()}


/**
 * add 3000 synapses to the given cell : approximately 80% exc, 20% inh
 * @param $o1 cell object to have synapses placed
 */
proc gensyns() { local synIndex, secIndex, nSec  localobj rngloc, rngtype, cell, synapse, nc, ips, tbins_vec, rate_vec, secList
    cell = $o1

    secList = new List()
    nSec = 0
    forsec cell.somatic {
        secList.append(new SectionRef())
        nSec = nSec+1
    }
    forsec cell.basal {
        secList.append(new SectionRef())
        nSec = nSec+1
    }
    forsec cell.apical {
        secList.append(new SectionRef())
        nSec = nSec+1
    }

    rngloc = new Random()
    rngloc.Random123(cell.gid, 101, 386)
    rngloc.uniform(0,nSec)

    rngtype = new Random()
    rngtype.Random123(cell.gid, 438, 295)
    rngtype.uniform(0,1)

    for synIndex=0, 2999 {
        secIndex = int(rngloc.repick())
        access secList.o(secIndex).sec

        if( rngtype.repick() < 0.8 ) {
            synapse = new ProbAMPANMDA_EMS(0.5)
        } else {
            synapse = new ProbGABAAB_EMS(0.5)
        }
        synapse.synapseID = synIndex
        synapse.setRNG( cell.gid+250, synIndex+100, 300 )
        cell.synlist.append(synapse)

        // enable spont minis
        ips = new InhPoissonStim(0.5)
        nc = new NetCon( ips, synapse )
        nc.delay = 0.1
        nc.weight = 1.0
        ips.setRNGs( synIndex+200, cell.gid+250, 300, synIndex+200, cell.gid+250, 350 )
        //if( cell.gid == 1 ) {
            //synapse.toggleVerbose()
        //}

        tbins_vec = new Vector(1)
        tbins_vec.x[0] = 0.0
        rate_vec = new Vector(1)
        rate_vec.x[0] = 0.04
        ips.setTbins( tbins_vec )
        ips.setRate( rate_vec )

        cell.synHelperList.append(ips)
        cell.synHelperList.append(nc)
        cell.synHelperList.append(tbins_vec)
        cell.synHelperList.append(rate_vec)
    }
}

// cycle through list until N total cells are instantiated
objref nil, nc
cellList = new List()

local_cell_index = 0

//timeit( "reset" )
for cellIndex=0, targetCount-1 {
    if( cellIndex % pnm.nhost != pnm.myid ) {
        continue
    }
    // distribute cell type uniformly in every rank
    offset = local_cell_index % typeCount
    local_cell_index = local_cell_index + 1

    strdef mFilePath
    sprint(mFilePath,"%s/%s/morphologies/", arg_datapath, arg_model)

    // assume all morphologies are 'asc' to simplify this code
    morph = load_morphology( mFilePath, morphList.o(offset).s, morphLookup )
    sprint( typeString.s, "cellInst = new %s( %d, %s )", etypeList.o(offset).s, cellIndex+1, morph )

    execute1( typeString.s )
    cellList.append( cellInst )
    //timeit("add cell")

    cellInst.connect2target( nil, nc )
    pnm.set_gid2node(cellIndex+1, pnm.myid)
    pnm.pc.cell( cellIndex+1, nc )
    pnm.spike_record( cellIndex+1 )
    //print pnm.myid, " ", cellIndex+1
    if( pnm.myid == 0 ) { print "    Instatiated ", cellIndex, " cell of type ", offset }

    //randomly distribute synapses 70% ProbAMPANMDA, 30% ProbGABAAB
    // todo - build sectionref array, for given syn count throw random numbers for synapse location (activation? could use finitializer callback)
    gensyns(cellInst)
    //timeit("add syns")
}
{pnm.pc.multisplit()}

if( pnm.myid == 0 ) { print "done cells" }

// stimulus
objref stimList
stimList = new List()
for cellIndex=0, cellList.count()-1 {
    access cellList.o(cellIndex).soma
    stimList.append( new IClamp(0.5) )
    stimList.o(cellIndex).amp = 1.15
    stimList.o(cellIndex).dur = 10000
}

objref cvode
cvode = new CVode()

{cvode.cache_efficient(1)}
{pnm.pc.nthread(1, 0)}

stdinit()

// debugging - report a cell
objref vvec
vvec = new Vector()
if( pnm.myid == 0 ) {
    print "add report"
    {access cellList.o(0).soma}
    vvec.record( &v(0.5), 0.1 )
}



/*
objref rfile
if( pnm.myid == 0 && vvec.size() > 0 ) {
    rfile = new File( "trace.txt" )
    rfile.wopen()
    for vindex=0, vvec.size()-1 {
        rfile.printf( "%f\n", vvec.x[vindex] )
    }
    rfile.close()
}
*/

proc prun() { localobj py_obj

    // dump model to file
    if (use_coreneuron_filemode || dump_coreneuron_model) {
        strdef outputPath
        sprint(outputPath,"coredat")
        if( pnm.myid == 0 ) {
            print "Starting CoreNEURON data generation"
        }
        pnm.pc.nrnbbcore_write(outputPath)

        // if only model dump mode then finish without running sim
        if (dump_coreneuron_model) {
            if (pnm.pc.id == 0) {
                print "dump_coreneuron_model=1, finishing execution without simulation\n"
            }
            return
        }
    }

    if( pnm.myid == 0 ) { print "Starting Simulation"}

    if (use_coreneuron) {
        if (!nrnpython("from neuron import coreneuron")) {
            execerror("Python not available, can not import coreneuron module\n")
        }
        py_obj = new PythonObject()
        py_obj.coreneuron.enable = 1
        py_obj.coreneuron.gpu = use_coreneuron_gpu
        py_obj.coreneuron.filemode = use_coreneuron_filemode
        py_obj.coreneuron.prcellstate = prcell_gid
    }
    if( prcell_gid != -1 && !use_coreneuron ) {
        strdef suffix
        sprint(suffix, "t_%lf", pnm.pc.t(0))
        pnm.pc.prcellstate(prcell_gid, suffix)
    }
    tsav = startsw()
    pnm.pc.set_maxstep(4)
    pnm.pc.timeout(200)
    pnm.psolve(tstop)

    if (pnm.pc.id == 0) {
        printf("psolve time %g seconds [tstop %g]\n", startsw() - tsav, tstop)
    }
    if( prcell_gid != -1 && !use_coreneuron ) {
        strdef suffix
        sprint(suffix, "t_%lf", pnm.pc.t(0))
        pnm.pc.prcellstate(prcell_gid, suffix)
    }
}

proc spike2file() { localobj outf, s
    s = new String()
    sprint(s.s, "out.dat")
    outf = new File()
    if (pnm.pc.id == 0) {outf.wopen(s.s) outf.close }
    for pnm.serialize() {
        outf.aopen(s.s)
        for spikeIndex=0, pnm.spikevec.size()-1 {
            outf.printf("%.8g\t%d\n", pnm.spikevec.x[spikeIndex], pnm.idvec.x[spikeIndex])
        }
        outf.close
    }
}

prun()
if (!dump_coreneuron_model) {
    spike2file()
}
quit()
